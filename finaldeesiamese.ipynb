{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.8.16","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-06-03T13:00:04.993911Z","iopub.execute_input":"2023-06-03T13:00:04.994506Z","iopub.status.idle":"2023-06-03T13:00:06.230183Z","shell.execute_reply.started":"2023-06-03T13:00:04.994478Z","shell.execute_reply":"2023-06-03T13:00:06.229156Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/segment/21_0_8019.png\n/kaggle/input/segment/23_manual1.gif\n/kaggle/input/segment/37_0_3779.png\n/kaggle/input/segment/38_0_4273.png\n/kaggle/input/segment/38_manual1.gif\n/kaggle/input/segment/35_manual1.gif\n/kaggle/input/segment/36_0_3768.png\n/kaggle/input/segment/31_0_9189.png\n/kaggle/input/segment/30_manual1.gif\n/kaggle/input/segment/34_manual1.gif\n/kaggle/input/segment/27_0_142.png\n/kaggle/input/segment/27_manual1.gif\n/kaggle/input/segment/29_manual1.gif\n/kaggle/input/segment/29_0_478.png\n/kaggle/input/segment/22_0_4498.png\n/kaggle/input/segment/24_0_3480.png\n/kaggle/input/segment/22_manual1.gif\n/kaggle/input/segment/39_0_9807.png\n/kaggle/input/segment/40_0_3246.png\n/kaggle/input/segment/33_0_6318.png\n/kaggle/input/segment/25_manual1.gif\n/kaggle/input/segment/28_0_1954.png\n/kaggle/input/segment/32_0_1886.png\n/kaggle/input/segment/25_0_651.png\n/kaggle/input/segment/30_0_3252.png\n/kaggle/input/segment/33_manual1.gif\n/kaggle/input/segment/39_manual1.gif\n/kaggle/input/segment/36_manual1.gif\n/kaggle/input/segment/26_0_2498.png\n/kaggle/input/segment/21_manual1.gif\n/kaggle/input/segment/34_0_4626.png\n/kaggle/input/segment/37_manual1.gif\n/kaggle/input/segment/24_manual1.gif\n/kaggle/input/segment/23_0_8546.png\n/kaggle/input/segment/32_manual1.gif\n/kaggle/input/segment/31_manual1.gif\n/kaggle/input/segment/40_manual1.gif\n/kaggle/input/segment/26_manual1.gif\n/kaggle/input/segment/35_0_8863.png\n/kaggle/input/segment/28_manual1.gif\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport random\nimport numpy as np\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\n\ndef create_positive_pairs(dataset_path):\n    pairs = []\n    labels = []\n    \n    filenames = sorted(os.listdir(dataset_path))\n    positives = []\n    \n    # Group the filenames into positive pairs\n    for i in range(0, len(filenames), 2):\n        image_path_1 = os.path.join(dataset_path, filenames[i])\n        image_path_2 = os.path.join(dataset_path, filenames[i+1])\n        \n        if filenames[i][:2] == filenames[i+1][:2]:\n            positives.append([image_path_1, image_path_2])\n    \n    # Check if there are enough positive pairs\n    if len(positives) < 20:\n        raise ValueError(\"Not enough positive pairs in the dataset.\")\n    \n    # Shuffle the positive pairs\n    random.shuffle(positives)\n    \n    # Take 20 positive pairs\n    pairs.extend(positives[:20])\n    labels.extend([1] * 20)  # Positive pair\n    \n    return pairs, labels\n\ndef create_negative_pairs(dataset_path):\n    pairs = []\n    labels = []\n    \n    filenames = sorted(os.listdir(dataset_path))\n    negatives = []\n    \n    # Group the filenames into negative pairs\n    for i in range(len(filenames)):\n        for j in range(i+1, len(filenames)):\n            image_path_1 = os.path.join(dataset_path, filenames[i])\n            image_path_2 = os.path.join(dataset_path, filenames[j])\n            \n            if filenames[i][:2] != filenames[j][:2]:\n                negatives.append([image_path_1, image_path_2])\n    \n    # Check if there are enough negative pairs\n    if len(negatives) < 15:\n        raise ValueError(\"Not enough negative pairs in the dataset.\")\n    \n    # Shuffle the negative pairs\n    random.shuffle(negatives)\n    \n    # Take 15 negative pairs\n    pairs.extend(negatives[:15])\n    labels.extend([0] * 15)  # Negative pair\n    \n    return pairs, labels\n\n# Define the path to the dataset folder\ndataset_path = '/kaggle/input/segment'\n\n# Create positive pairs\npositive_pairs, positive_labels = create_positive_pairs(dataset_path)\n\n# Create negative pairs\nnegative_pairs, negative_labels = create_negative_pairs(dataset_path)\n\n# Combine positive and negative pairs\npairs = positive_pairs + negative_pairs\nlabels = positive_labels + negative_labels\n\n# Shuffle the pairs and labels\ncombined_data = list(zip(pairs, labels))\nrandom.shuffle(combined_data)\npairs, labels = zip(*combined_data)\n\n# Convert pairs and labels to numpy arrays\npairs = np.array(pairs)\nlabels = np.array(labels)\n\n# Split into training and testing sets with a balanced distribution\ntrain_ratio = 0.8\nnum_positive_pairs = len(positive_pairs)\nnum_negative_pairs = len(negative_pairs)\n\n# Calculate the number of positive and negative pairs for training and testing\nnum_positive_train = int(train_ratio * num_positive_pairs)\nnum_positive_test = num_positive_pairs - num_positive_train\nnum_negative_train = int(train_ratio * num_negative_pairs)\nnum_negative_test = num_negative_pairs - num_negative_train\n\n# Select the corresponding pairs and labels for training and testing\ntrain_input_pairs = np.concatenate((pairs[:num_positive_train], pairs[num_positive_pairs:num_positive_pairs+num_negative_train]), axis=0)\ntrain_labels = np.concatenate((labels[:num_positive_train], labels[num_positive_pairs:num_positive_pairs+num_negative_train]), axis=0)\ntest_input_pairs = np.concatenate((pairs[num_positive_train:num_positive_pairs], pairs[num_positive_pairs+num_negative_train:]), axis=0)\ntest_labels = np.concatenate((labels[num_positive_train:num_positive_pairs], labels[num_positive_pairs+num_negative_train:]), axis=0)","metadata":{"execution":{"iopub.status.busy":"2023-06-03T13:16:03.620708Z","iopub.execute_input":"2023-06-03T13:16:03.621753Z","iopub.status.idle":"2023-06-03T13:16:03.652075Z","shell.execute_reply.started":"2023-06-03T13:16:03.621715Z","shell.execute_reply":"2023-06-03T13:16:03.651029Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"train_input_pairs.shape","metadata":{"execution":{"iopub.status.busy":"2023-06-03T13:46:11.467719Z","iopub.execute_input":"2023-06-03T13:46:11.468748Z","iopub.status.idle":"2023-06-03T13:46:11.474637Z","shell.execute_reply.started":"2023-06-03T13:46:11.468708Z","shell.execute_reply":"2023-06-03T13:46:11.473594Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"(28, 2)"},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\nfrom tensorflow.keras.applications.resnet50 import preprocess_input\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Lambda\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import Nadam\nfrom tensorflow.keras import backend as K","metadata":{"execution":{"iopub.status.busy":"2023-06-03T13:07:37.916663Z","iopub.execute_input":"2023-06-03T13:07:37.917085Z","iopub.status.idle":"2023-06-03T13:08:17.086615Z","shell.execute_reply.started":"2023-06-03T13:07:37.917054Z","shell.execute_reply":"2023-06-03T13:08:17.085496Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"D0603 13:08:09.913040398      14 config.cc:119]                        gRPC EXPERIMENT tcp_frame_size_tuning               OFF (default:OFF)\nD0603 13:08:09.913071447      14 config.cc:119]                        gRPC EXPERIMENT tcp_rcv_lowat                       OFF (default:OFF)\nD0603 13:08:09.913074736      14 config.cc:119]                        gRPC EXPERIMENT peer_state_based_framing            OFF (default:OFF)\nD0603 13:08:09.913077550      14 config.cc:119]                        gRPC EXPERIMENT flow_control_fixes                  ON  (default:ON)\nD0603 13:08:09.913079907      14 config.cc:119]                        gRPC EXPERIMENT memory_pressure_controller          OFF (default:OFF)\nD0603 13:08:09.913082479      14 config.cc:119]                        gRPC EXPERIMENT unconstrained_max_quota_buffer_size OFF (default:OFF)\nD0603 13:08:09.913084971      14 config.cc:119]                        gRPC EXPERIMENT new_hpack_huffman_decoder           ON  (default:ON)\nD0603 13:08:09.913087631      14 config.cc:119]                        gRPC EXPERIMENT event_engine_client                 OFF (default:OFF)\nD0603 13:08:09.913089910      14 config.cc:119]                        gRPC EXPERIMENT monitoring_experiment               ON  (default:ON)\nD0603 13:08:09.913092189      14 config.cc:119]                        gRPC EXPERIMENT promise_based_client_call           OFF (default:OFF)\nD0603 13:08:09.913094408      14 config.cc:119]                        gRPC EXPERIMENT free_large_allocator                OFF (default:OFF)\nD0603 13:08:09.913096651      14 config.cc:119]                        gRPC EXPERIMENT promise_based_server_call           OFF (default:OFF)\nD0603 13:08:09.913098981      14 config.cc:119]                        gRPC EXPERIMENT transport_supplies_client_latency   OFF (default:OFF)\nD0603 13:08:09.913101251      14 config.cc:119]                        gRPC EXPERIMENT event_engine_listener               OFF (default:OFF)\nI0603 13:08:09.913297985      14 ev_epoll1_linux.cc:122]               grpc epoll fd: 66\nD0603 13:08:09.913309453      14 ev_posix.cc:144]                      Using polling engine: epoll1\nD0603 13:08:09.913327274      14 dns_resolver_ares.cc:822]             Using ares dns resolver\nD0603 13:08:09.913771524      14 lb_policy_registry.cc:46]             registering LB policy factory for \"priority_experimental\"\nD0603 13:08:09.913781205      14 lb_policy_registry.cc:46]             registering LB policy factory for \"outlier_detection_experimental\"\nD0603 13:08:09.913784733      14 lb_policy_registry.cc:46]             registering LB policy factory for \"weighted_target_experimental\"\nD0603 13:08:09.913798469      14 lb_policy_registry.cc:46]             registering LB policy factory for \"pick_first\"\nD0603 13:08:09.913802013      14 lb_policy_registry.cc:46]             registering LB policy factory for \"round_robin\"\nD0603 13:08:09.913804848      14 lb_policy_registry.cc:46]             registering LB policy factory for \"weighted_round_robin_experimental\"\nD0603 13:08:09.913811118      14 lb_policy_registry.cc:46]             registering LB policy factory for \"ring_hash_experimental\"\nD0603 13:08:09.913822936      14 lb_policy_registry.cc:46]             registering LB policy factory for \"grpclb\"\nD0603 13:08:09.913847550      14 lb_policy_registry.cc:46]             registering LB policy factory for \"rls_experimental\"\nD0603 13:08:09.913862198      14 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_cluster_manager_experimental\"\nD0603 13:08:09.913865533      14 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_cluster_impl_experimental\"\nD0603 13:08:09.913868554      14 lb_policy_registry.cc:46]             registering LB policy factory for \"cds_experimental\"\nD0603 13:08:09.913871915      14 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_cluster_resolver_experimental\"\nD0603 13:08:09.913874828      14 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_override_host_experimental\"\nD0603 13:08:09.913877596      14 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_wrr_locality_experimental\"\nD0603 13:08:09.913881499      14 certificate_provider_registry.cc:35]  registering certificate provider factory for \"file_watcher\"\nI0603 13:08:09.916208828      14 socket_utils_common_posix.cc:408]     Disabling AF_INET6 sockets because ::1 is not available.\nI0603 13:08:09.941708682     304 socket_utils_common_posix.cc:337]     TCP_USER_TIMEOUT is available. TCP_USER_TIMEOUT will be used thereafter\nE0603 13:08:09.959661965     304 oauth2_credentials.cc:236]            oauth_fetch: UNKNOWN:C-ares status is not ARES_SUCCESS qtype=A name=metadata.google.internal. is_balancer=0: Domain name not found {grpc_status:2, created_time:\"2023-06-03T13:08:09.959644023+00:00\"}\n","output_type":"stream"}]},{"cell_type":"code","source":"from keras.optimizers import Adam\nfrom keras.callbacks import ReduceLROnPlateau","metadata":{"execution":{"iopub.status.busy":"2023-06-03T13:08:21.565312Z","iopub.execute_input":"2023-06-03T13:08:21.566031Z","iopub.status.idle":"2023-06-03T13:08:21.571436Z","shell.execute_reply.started":"2023-06-03T13:08:21.565994Z","shell.execute_reply":"2023-06-03T13:08:21.570351Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Lambda\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.losses import binary_crossentropy\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\n\n# Define the input shape\ninput_shape = (256, 256, 3)\n\n# Define the Siamese network architecture\ndef build_siamese_network(input_shape):\n    input_image = Input(shape=input_shape)\n\n    model = Conv2D(64, (10, 10), activation='relu')(input_image)\n    model = MaxPooling2D()(model)\n    model = Conv2D(128, (7, 7), activation='relu')(model)\n    model = MaxPooling2D()(model)\n    model = Conv2D(128, (4, 4), activation='relu')(model)\n    model = MaxPooling2D()(model)\n    model = Conv2D(256, (4, 4), activation='relu')(model)\n    model = Flatten()(model)\n    model = Dense(4096, activation='sigmoid')(model)\n\n    encoded_image = model\n\n    siamese_model = Model(input_image, encoded_image)\n    return siamese_model\n\n# Create the Siamese network model\nsiamese_model = build_siamese_network(input_shape)\n\n# Compile the model with appropriate loss and optimizer\nsiamese_model.compile(loss=binary_crossentropy, optimizer=Adam(learning_rate=0.001))\n\n# Generate some dummy training data\ntrain_input_pairs = np.random.randn(28, 2, *input_shape)\ntest_input_pairs = np.random.randn(7, 2, *input_shape)\ntrain_labels = np.random.randint(0, 2, size=(28,))\ntest_labels = np.random.randint(0, 2, size=(7,))\n\n# Reshape the input pairs for training\ntrain_input_pairs_reshaped = np.reshape(train_input_pairs, (train_input_pairs.shape[0], 2, *input_shape))\ntest_input_pairs_reshaped = np.reshape(test_input_pairs, (test_input_pairs.shape[0], 2, *input_shape))\n\n# Define a custom distance function for comparing the encoded features\ndef euclidean_distance(vectors):\n    vector1, vector2 = vectors\n    sum_squared = tf.reduce_sum(tf.square(vector1 - vector2), axis=1, keepdims=True)\n    return tf.sqrt(sum_squared)\n\n# Define the siamese network with the distance function\ninput_image_1 = Input(shape=input_shape)\ninput_image_2 = Input(shape=input_shape)\n\nencoded_image_1 = siamese_model(input_image_1)\nencoded_image_2 = siamese_model(input_image_2)\n\ndistance = Lambda(euclidean_distance)([encoded_image_1, encoded_image_2])\n\nsiamese_network = Model(inputs=[input_image_1, input_image_2], outputs=distance)\n\n# Compile the siamese network\nsiamese_network.compile(loss=binary_crossentropy, optimizer=Adam(learning_rate=0.001))\n\nsiamese_network.fit([train_input_pairs_reshaped[:, 0], train_input_pairs_reshaped[:, 1]], train_labels, \n                    validation_data=([test_input_pairs_reshaped[:, 0], test_input_pairs_reshaped[:, 1]], test_labels), \n                    batch_size=8, epochs=50)\n\n# Evaluate the model on the testing data\nresult = siamese_network.evaluate([test_input_pairs_reshaped[:, 0], test_input_pairs_reshaped[:, 1]], test_labels)\nloss = result[0]\naccuracy = result[1]\n\nprint(\"Testing Loss: {:.4f}\".format(loss))\nprint(\"Testing Accuracy: {:.2f}%\".format(accuracy * 100))\n","metadata":{"execution":{"iopub.status.busy":"2023-06-03T13:59:37.233905Z","iopub.execute_input":"2023-06-03T13:59:37.234971Z","iopub.status.idle":"2023-06-03T14:11:17.014509Z","shell.execute_reply.started":"2023-06-03T13:59:37.234934Z","shell.execute_reply":"2023-06-03T14:11:17.013104Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"Epoch 1/50\n4/4 [==============================] - 15s 3s/step - loss: 0.7982 - val_loss: 0.7148\nEpoch 2/50\n4/4 [==============================] - 14s 3s/step - loss: 1.1270 - val_loss: 0.7363\nEpoch 3/50\n4/4 [==============================] - 13s 3s/step - loss: 0.9282 - val_loss: 0.6888\nEpoch 4/50\n4/4 [==============================] - 14s 3s/step - loss: 1.6221 - val_loss: 0.5693\nEpoch 5/50\n4/4 [==============================] - 14s 3s/step - loss: 1.2837 - val_loss: 1.0602\nEpoch 6/50\n4/4 [==============================] - 14s 3s/step - loss: 2.3266 - val_loss: 0.7293\nEpoch 7/50\n4/4 [==============================] - 14s 3s/step - loss: 1.0553 - val_loss: 0.9000\nEpoch 8/50\n4/4 [==============================] - 14s 3s/step - loss: 0.8891 - val_loss: 0.7926\nEpoch 9/50\n4/4 [==============================] - 14s 3s/step - loss: 1.7739 - val_loss: 0.8726\nEpoch 10/50\n4/4 [==============================] - 14s 3s/step - loss: 5.4599 - val_loss: 4.3043\nEpoch 11/50\n4/4 [==============================] - 14s 3s/step - loss: 7.2457 - val_loss: 0.7730\nEpoch 12/50\n4/4 [==============================] - 14s 4s/step - loss: 2.1313 - val_loss: 0.6014\nEpoch 13/50\n4/4 [==============================] - 14s 3s/step - loss: 0.8451 - val_loss: 0.7525\nEpoch 14/50\n4/4 [==============================] - 13s 3s/step - loss: 0.4328 - val_loss: 4.9570\nEpoch 15/50\n4/4 [==============================] - 14s 3s/step - loss: 0.9522 - val_loss: 4.9337\nEpoch 16/50\n4/4 [==============================] - 14s 3s/step - loss: 0.9134 - val_loss: 1.0347\nEpoch 17/50\n4/4 [==============================] - 14s 3s/step - loss: 1.4875 - val_loss: 0.7878\nEpoch 18/50\n4/4 [==============================] - 14s 3s/step - loss: 1.0516 - val_loss: 0.9574\nEpoch 19/50\n4/4 [==============================] - 14s 4s/step - loss: 0.6666 - val_loss: 0.7383\nEpoch 20/50\n4/4 [==============================] - 14s 3s/step - loss: 0.8807 - val_loss: 1.1698\nEpoch 21/50\n4/4 [==============================] - 14s 4s/step - loss: 1.2320 - val_loss: 0.7231\nEpoch 22/50\n4/4 [==============================] - 14s 4s/step - loss: 1.4140 - val_loss: 0.7930\nEpoch 23/50\n4/4 [==============================] - 14s 4s/step - loss: 1.4830 - val_loss: 0.5833\nEpoch 24/50\n4/4 [==============================] - 14s 4s/step - loss: 2.0227 - val_loss: 1.0257\nEpoch 25/50\n4/4 [==============================] - 14s 3s/step - loss: 2.1942 - val_loss: 0.8692\nEpoch 26/50\n4/4 [==============================] - 14s 4s/step - loss: 1.6818 - val_loss: 0.7481\nEpoch 27/50\n4/4 [==============================] - 14s 4s/step - loss: 1.2256 - val_loss: 0.8084\nEpoch 28/50\n4/4 [==============================] - 14s 3s/step - loss: 1.3588 - val_loss: 0.9399\nEpoch 29/50\n4/4 [==============================] - 14s 3s/step - loss: 1.6274 - val_loss: 0.7429\nEpoch 30/50\n4/4 [==============================] - 14s 4s/step - loss: 1.2718 - val_loss: 0.8624\nEpoch 31/50\n4/4 [==============================] - 14s 3s/step - loss: 1.0296 - val_loss: 0.7330\nEpoch 32/50\n4/4 [==============================] - 14s 3s/step - loss: 1.0192 - val_loss: 0.7728\nEpoch 33/50\n4/4 [==============================] - 14s 3s/step - loss: 1.0750 - val_loss: 0.7107\nEpoch 34/50\n4/4 [==============================] - 14s 3s/step - loss: 1.0061 - val_loss: 0.8358\nEpoch 35/50\n4/4 [==============================] - 14s 3s/step - loss: 0.7697 - val_loss: 0.9339\nEpoch 36/50\n4/4 [==============================] - 14s 3s/step - loss: 0.8830 - val_loss: 0.6785\nEpoch 37/50\n4/4 [==============================] - 14s 3s/step - loss: 0.7714 - val_loss: 1.0252\nEpoch 38/50\n4/4 [==============================] - 14s 4s/step - loss: 0.4019 - val_loss: 1.0816\nEpoch 39/50\n4/4 [==============================] - 14s 3s/step - loss: 0.4383 - val_loss: 1.0806\nEpoch 40/50\n4/4 [==============================] - 14s 3s/step - loss: 0.2849 - val_loss: 1.1735\nEpoch 41/50\n4/4 [==============================] - 14s 3s/step - loss: 0.4318 - val_loss: 1.1312\nEpoch 42/50\n4/4 [==============================] - 14s 4s/step - loss: 0.1635 - val_loss: 1.2264\nEpoch 43/50\n4/4 [==============================] - 14s 4s/step - loss: 0.1726 - val_loss: 1.2430\nEpoch 44/50\n4/4 [==============================] - 14s 3s/step - loss: 0.0622 - val_loss: 1.3352\nEpoch 45/50\n4/4 [==============================] - 14s 3s/step - loss: 0.0331 - val_loss: 1.5142\nEpoch 46/50\n4/4 [==============================] - 14s 3s/step - loss: 0.0245 - val_loss: 1.3200\nEpoch 47/50\n4/4 [==============================] - 14s 3s/step - loss: 0.0173 - val_loss: 1.2876\nEpoch 48/50\n4/4 [==============================] - 14s 3s/step - loss: 0.0150 - val_loss: 1.3537\nEpoch 49/50\n4/4 [==============================] - 14s 4s/step - loss: 0.0159 - val_loss: 1.3553\nEpoch 50/50\n4/4 [==============================] - 14s 4s/step - loss: 0.0128 - val_loss: 1.2982\n1/1 [==============================] - 0s 220ms/step - loss: 1.2982\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[32], line 73\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# Evaluate the model on the testing data\u001b[39;00m\n\u001b[1;32m     72\u001b[0m result \u001b[38;5;241m=\u001b[39m siamese_network\u001b[38;5;241m.\u001b[39mevaluate([test_input_pairs_reshaped[:, \u001b[38;5;241m0\u001b[39m], test_input_pairs_reshaped[:, \u001b[38;5;241m1\u001b[39m]], test_labels)\n\u001b[0;32m---> 73\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     74\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTesting Loss: \u001b[39m\u001b[38;5;132;01m{:.4f}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(loss))\n","\u001b[0;31mTypeError\u001b[0m: 'float' object is not subscriptable"],"ename":"TypeError","evalue":"'float' object is not subscriptable","output_type":"error"}]},{"cell_type":"code","source":"# Calculate training accuracy\ntrain_pred = siamese_network.predict([train_input_pairs_reshaped[:, 0], train_input_pairs_reshaped[:, 1]])\ntrain_pred = np.round(train_pred).flatten()\ntrain_accuracy = np.mean(train_pred == train_labels)\n\n# Calculate testing accuracy\ntest_pred = siamese_network.predict([test_input_pairs_reshaped[:, 0], test_input_pairs_reshaped[:, 1]])\ntest_pred = np.round(test_pred).flatten()\ntest_accuracy = np.mean(test_pred == test_labels)\n\nprint(\"Training Accuracy: {:.2f}%\".format(train_accuracy * 100))\nprint(\"Testing Accuracy: {:.2f}%\".format(test_accuracy * 100))","metadata":{"execution":{"iopub.status.busy":"2023-06-03T14:15:53.864856Z","iopub.execute_input":"2023-06-03T14:15:53.865824Z","iopub.status.idle":"2023-06-03T14:15:54.952356Z","shell.execute_reply.started":"2023-06-03T14:15:53.865775Z","shell.execute_reply":"2023-06-03T14:15:54.951073Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 1s 731ms/step\n1/1 [==============================] - 0s 225ms/step\nTraining Accuracy: 100.00%\nTesting Accuracy: 57.14%\n","output_type":"stream"}]},{"cell_type":"code","source":"train_pred = siamese_network.predict([train_input_pairs_reshaped[:, 0], train_input_pairs_reshaped[:, 1]])\ntrain_pred = np.round(train_pred).flatten()\ntrain_accuracy = np.mean(train_pred == train_labels)\n\n# Calculate testing accuracy\ntest_pred = siamese_network.predict([test_input_pairs_reshaped[:, 0], test_input_pairs_reshaped[:, 1]])\ntest_pred = np.round(test_pred).flatten()\ntest_accuracy = np.mean(test_pred == test_labels)\n\nprint(\"Training Accuracy: {:.2f}%\".format(train_accuracy * 100))\nprint(\"Testing Accuracy: {:.2f}%\".format(test_accuracy * 100))","metadata":{"execution":{"iopub.status.busy":"2023-06-03T14:16:06.771939Z","iopub.execute_input":"2023-06-03T14:16:06.772306Z","iopub.status.idle":"2023-06-03T14:16:07.850265Z","shell.execute_reply.started":"2023-06-03T14:16:06.772279Z","shell.execute_reply":"2023-06-03T14:16:07.848973Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 1s 726ms/step\n1/1 [==============================] - 0s 216ms/step\nTraining Accuracy: 100.00%\nTesting Accuracy: 57.14%\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Lambda\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.losses import binary_crossentropy\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\n\n# Define the input shape\ninput_shape = (256, 256, 3)\n\n# Define the Siamese network architecture\ndef build_siamese_network(input_shape):\n    input_image = Input(shape=input_shape)\n\n    model = Conv2D(64, (10, 10), activation='relu')(input_image)\n    model = MaxPooling2D()(model)\n    model = Conv2D(128, (7, 7), activation='relu')(model)\n    model = MaxPooling2D()(model)\n    model = Conv2D(128, (4, 4), activation='relu')(model)\n    model = MaxPooling2D()(model)\n    model = Conv2D(256, (4, 4), activation='relu')(model)\n    model = Flatten()(model)\n    model = Dense(4096, activation='sigmoid')(model)\n\n    encoded_image = model\n\n    siamese_model = Model(input_image, encoded_image)\n    return siamese_model\n\n# Create the Siamese network model\nsiamese_model = build_siamese_network(input_shape)\n\n# Compile the model with appropriate loss and optimizer\nsiamese_model.compile(loss=binary_crossentropy, optimizer=Adam(learning_rate=0.001))\n\n# Generate some dummy training data\ntrain_input_pairs = np.random.randn(28, 2, *input_shape)\ntest_input_pairs = np.random.randn(7, 2, *input_shape)\ntrain_labels = np.random.randint(0, 2, size=(28,))\ntest_labels = np.random.randint(0, 2, size=(7,))\n\n# Reshape the input pairs for training\ntrain_input_pairs_reshaped = np.reshape(train_input_pairs, (train_input_pairs.shape[0], 2, *input_shape))\ntest_input_pairs_reshaped = np.reshape(test_input_pairs, (test_input_pairs.shape[0], 2, *input_shape))\n\n# Define a custom distance function for comparing the encoded features\ndef euclidean_distance(vectors):\n    vector1, vector2 = vectors\n    sum_squared = tf.reduce_sum(tf.square(vector1 - vector2), axis=1, keepdims=True)\n    return tf.sqrt(sum_squared)\n\n# Define the siamese network with the distance function\ninput_image_1 = Input(shape=input_shape)\ninput_image_2 = Input(shape=input_shape)\n\nencoded_image_1 = siamese_model(input_image_1)\nencoded_image_2 = siamese_model(input_image_2)\n\ndistance = Lambda(euclidean_distance)([encoded_image_1, encoded_image_2])\n\nsiamese_network = Model(inputs=[input_image_1, input_image_2], outputs=distance)\n\n# Compile the siamese network\nsiamese_network.compile(loss=binary_crossentropy, optimizer=Adam(learning_rate=0.0001))\n\nsiamese_network.fit([train_input_pairs_reshaped[:, 0], train_input_pairs_reshaped[:, 1]], train_labels, \n                    validation_data=([test_input_pairs_reshaped[:, 0], test_input_pairs_reshaped[:, 1]], test_labels), \n                    batch_size=32, epochs=50)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-06-03T14:17:02.092329Z","iopub.execute_input":"2023-06-03T14:17:02.093464Z","iopub.status.idle":"2023-06-03T14:22:23.657314Z","shell.execute_reply.started":"2023-06-03T14:17:02.093422Z","shell.execute_reply":"2023-06-03T14:22:23.656038Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"Epoch 1/50\n1/1 [==============================] - 8s 8s/step - loss: 1.3101 - val_loss: 0.8990\nEpoch 2/50\n1/1 [==============================] - 6s 6s/step - loss: 0.5419 - val_loss: 0.7676\nEpoch 3/50\n1/1 [==============================] - 6s 6s/step - loss: 0.6379 - val_loss: 0.6895\nEpoch 4/50\n1/1 [==============================] - 6s 6s/step - loss: 0.5232 - val_loss: 0.6627\nEpoch 5/50\n1/1 [==============================] - 6s 6s/step - loss: 0.4059 - val_loss: 0.6555\nEpoch 6/50\n1/1 [==============================] - 6s 6s/step - loss: 0.2793 - val_loss: 0.6576\nEpoch 7/50\n1/1 [==============================] - 6s 6s/step - loss: 0.1729 - val_loss: 0.6503\nEpoch 8/50\n1/1 [==============================] - 6s 6s/step - loss: 0.1160 - val_loss: 0.6415\nEpoch 9/50\n1/1 [==============================] - 6s 6s/step - loss: 0.0841 - val_loss: 0.6340\nEpoch 10/50\n1/1 [==============================] - 6s 6s/step - loss: 0.0843 - val_loss: 0.6272\nEpoch 11/50\n1/1 [==============================] - 6s 6s/step - loss: 0.0904 - val_loss: 0.6219\nEpoch 12/50\n1/1 [==============================] - 6s 6s/step - loss: 0.0877 - val_loss: 0.6169\nEpoch 13/50\n1/1 [==============================] - 6s 6s/step - loss: 0.0802 - val_loss: 0.6116\nEpoch 14/50\n1/1 [==============================] - 6s 6s/step - loss: 0.0670 - val_loss: 0.6067\nEpoch 15/50\n1/1 [==============================] - 6s 6s/step - loss: 0.0527 - val_loss: 0.6034\nEpoch 16/50\n1/1 [==============================] - 6s 6s/step - loss: 0.0450 - val_loss: 0.6011\nEpoch 17/50\n1/1 [==============================] - 6s 6s/step - loss: 0.0401 - val_loss: 0.5996\nEpoch 18/50\n1/1 [==============================] - 6s 6s/step - loss: 0.0379 - val_loss: 0.5988\nEpoch 19/50\n1/1 [==============================] - 6s 6s/step - loss: 0.0356 - val_loss: 0.5990\nEpoch 20/50\n1/1 [==============================] - 6s 6s/step - loss: 0.0316 - val_loss: 0.6001\nEpoch 21/50\n1/1 [==============================] - 6s 6s/step - loss: 0.0273 - val_loss: 0.6023\nEpoch 22/50\n1/1 [==============================] - 6s 6s/step - loss: 0.0298 - val_loss: 0.5998\nEpoch 23/50\n1/1 [==============================] - 6s 6s/step - loss: 0.0308 - val_loss: 0.5993\nEpoch 24/50\n1/1 [==============================] - 6s 6s/step - loss: 0.0302 - val_loss: 0.5995\nEpoch 25/50\n1/1 [==============================] - 6s 6s/step - loss: 0.0255 - val_loss: 0.5999\nEpoch 26/50\n1/1 [==============================] - 6s 6s/step - loss: 0.0240 - val_loss: 0.6000\nEpoch 27/50\n1/1 [==============================] - 6s 6s/step - loss: 0.0211 - val_loss: 0.6004\nEpoch 28/50\n1/1 [==============================] - 6s 6s/step - loss: 0.0209 - val_loss: 0.6012\nEpoch 29/50\n1/1 [==============================] - 6s 6s/step - loss: 0.0186 - val_loss: 0.6025\nEpoch 30/50\n1/1 [==============================] - 6s 6s/step - loss: 0.0168 - val_loss: 0.6041\nEpoch 31/50\n1/1 [==============================] - 6s 6s/step - loss: 0.0152 - val_loss: 0.6056\nEpoch 32/50\n1/1 [==============================] - 6s 6s/step - loss: 0.0142 - val_loss: 0.6077\nEpoch 33/50\n1/1 [==============================] - 6s 6s/step - loss: 0.0129 - val_loss: 0.6105\nEpoch 34/50\n1/1 [==============================] - 6s 6s/step - loss: 0.0134 - val_loss: 0.6088\nEpoch 35/50\n1/1 [==============================] - 6s 6s/step - loss: 0.0112 - val_loss: 0.6080\nEpoch 36/50\n1/1 [==============================] - 6s 6s/step - loss: 0.0108 - val_loss: 0.6081\nEpoch 37/50\n1/1 [==============================] - 6s 6s/step - loss: 0.0095 - val_loss: 0.6086\nEpoch 38/50\n1/1 [==============================] - 6s 6s/step - loss: 0.0092 - val_loss: 0.6093\nEpoch 39/50\n1/1 [==============================] - 6s 6s/step - loss: 0.0089 - val_loss: 0.6106\nEpoch 40/50\n1/1 [==============================] - 6s 6s/step - loss: 0.0080 - val_loss: 0.6109\nEpoch 41/50\n1/1 [==============================] - 6s 6s/step - loss: 0.0074 - val_loss: 0.6116\nEpoch 42/50\n1/1 [==============================] - 6s 6s/step - loss: 0.0073 - val_loss: 0.6125\nEpoch 43/50\n1/1 [==============================] - 6s 6s/step - loss: 0.0068 - val_loss: 0.6137\nEpoch 44/50\n1/1 [==============================] - 6s 6s/step - loss: 0.0064 - val_loss: 0.6154\nEpoch 45/50\n1/1 [==============================] - 6s 6s/step - loss: 0.0063 - val_loss: 0.6169\nEpoch 46/50\n1/1 [==============================] - 6s 6s/step - loss: 0.0062 - val_loss: 0.6192\nEpoch 47/50\n1/1 [==============================] - 6s 6s/step - loss: 0.0061 - val_loss: 0.6212\nEpoch 48/50\n1/1 [==============================] - 6s 6s/step - loss: 0.0053 - val_loss: 0.6240\nEpoch 49/50\n1/1 [==============================] - 6s 6s/step - loss: 0.0072 - val_loss: 0.6153\nEpoch 50/50\n1/1 [==============================] - 6s 6s/step - loss: 0.0087 - val_loss: 0.6121\n","output_type":"stream"},{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7ef2040e9c10>"},"metadata":{}}]},{"cell_type":"code","source":"train_pred1 = siamese_network.predict([train_input_pairs_reshaped[:, 0], train_input_pairs_reshaped[:, 1]])\ntrain_pred1= np.round(train_pred1).flatten()\ntrain_accuracy1 = np.mean(train_pred1 == train_labels)\n\n# Calculate testing accuracy\ntest_pred1 = siamese_network.predict([test_input_pairs_reshaped[:, 0], test_input_pairs_reshaped[:, 1]])\ntest_pred1 = np.round(test_pred1).flatten()\ntest_accuracy1 = np.mean(test_pred1 == test_labels)\n\nprint(\"Training Accuracy: {:.2f}%\".format(train_accuracy1 * 100))\nprint(\"Testing Accuracy: {:.2f}%\".format(test_accuracy1 * 100))","metadata":{"execution":{"iopub.status.busy":"2023-06-03T14:24:02.686976Z","iopub.execute_input":"2023-06-03T14:24:02.687441Z","iopub.status.idle":"2023-06-03T14:24:03.919514Z","shell.execute_reply.started":"2023-06-03T14:24:02.687406Z","shell.execute_reply":"2023-06-03T14:24:03.918217Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 1s 847ms/step\n1/1 [==============================] - 0s 223ms/step\nTraining Accuracy: 100.00%\nTesting Accuracy: 71.43%\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Lambda\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.losses import binary_crossentropy\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\n\n# Define the input shape\ninput_shape = (256, 256, 3)\n\n# Define the Siamese network architecture\ndef build_siamese_network(input_shape):\n    input_image = Input(shape=input_shape)\n\n    model = Conv2D(64, (10, 10), activation='relu')(input_image)\n    model = MaxPooling2D()(model)\n    model = Conv2D(128, (7, 7), activation='relu')(model)\n    model = MaxPooling2D()(model)\n    model = Conv2D(128, (4, 4), activation='relu')(model)\n    model = MaxPooling2D()(model)\n    model = Conv2D(256, (4, 4), activation='relu')(model)\n    model = Flatten()(model)\n    model = Dense(4096, activation='sigmoid')(model)\n\n    encoded_image = model\n\n    siamese_model = Model(input_image, encoded_image)\n    return siamese_model\n\n# Create the Siamese network model\nsiamese_model = build_siamese_network(input_shape)\n\n# Compile the model with appropriate loss and optimizer\nsiamese_model.compile(loss=binary_crossentropy, optimizer=Adam(learning_rate=0.001))\n\n# Generate some dummy training data\ntrain_input_pairs = np.random.randn(28, 2, *input_shape)\ntest_input_pairs = np.random.randn(7, 2, *input_shape)\ntrain_labels = np.random.randint(0, 2, size=(28,))\ntest_labels = np.random.randint(0, 2, size=(7,))\n\n# Reshape the input pairs for training\ntrain_input_pairs_reshaped = np.reshape(train_input_pairs, (train_input_pairs.shape[0], 2, *input_shape))\ntest_input_pairs_reshaped = np.reshape(test_input_pairs, (test_input_pairs.shape[0], 2, *input_shape))\n\n# Define a custom distance function for comparing the encoded features\ndef euclidean_distance(vectors):\n    vector1, vector2 = vectors\n    sum_squared = tf.reduce_sum(tf.square(vector1 - vector2), axis=1, keepdims=True)\n    return tf.sqrt(sum_squared)\n\n# Define the siamese network with the distance function\ninput_image_1 = Input(shape=input_shape)\ninput_image_2 = Input(shape=input_shape)\n\nencoded_image_1 = siamese_model(input_image_1)\nencoded_image_2 = siamese_model(input_image_2)\n\ndistance = Lambda(euclidean_distance)([encoded_image_1, encoded_image_2])\n\nsiamese_network = Model(inputs=[input_image_1, input_image_2], outputs=distance)\n\n# Compile the siamese network\nsiamese_network.compile(loss=binary_crossentropy, optimizer=Adam(learning_rate=0.001))\n\nsiamese_network.fit([train_input_pairs_reshaped[:, 0], train_input_pairs_reshaped[:, 1]], train_labels, \n                    validation_data=([test_input_pairs_reshaped[:, 0], test_input_pairs_reshaped[:, 1]], test_labels), \n                    batch_size=32, epochs=50)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-06-03T14:25:28.289727Z","iopub.execute_input":"2023-06-03T14:25:28.290357Z","iopub.status.idle":"2023-06-03T14:30:49.867337Z","shell.execute_reply.started":"2023-06-03T14:25:28.290319Z","shell.execute_reply":"2023-06-03T14:30:49.865843Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"Epoch 1/50\n1/1 [==============================] - 8s 8s/step - loss: 5.9909 - val_loss: 4.8223\nEpoch 2/50\n1/1 [==============================] - 6s 6s/step - loss: 1.6324 - val_loss: 1.0089\nEpoch 3/50\n1/1 [==============================] - 6s 6s/step - loss: 2.5980 - val_loss: 1.8556\nEpoch 4/50\n1/1 [==============================] - 6s 6s/step - loss: 2.0769 - val_loss: 6.0597\nEpoch 5/50\n1/1 [==============================] - 6s 6s/step - loss: 8.1050 - val_loss: 6.6107\nEpoch 6/50\n1/1 [==============================] - 6s 6s/step - loss: 9.3651 - val_loss: 6.6107\nEpoch 7/50\n1/1 [==============================] - 6s 6s/step - loss: 9.3651 - val_loss: 6.6107\nEpoch 8/50\n1/1 [==============================] - 6s 6s/step - loss: 9.3651 - val_loss: 6.6107\nEpoch 9/50\n1/1 [==============================] - 6s 6s/step - loss: 9.3651 - val_loss: 6.6107\nEpoch 10/50\n1/1 [==============================] - 6s 6s/step - loss: 9.3651 - val_loss: 6.6107\nEpoch 11/50\n1/1 [==============================] - 6s 6s/step - loss: 9.3651 - val_loss: 6.6107\nEpoch 12/50\n1/1 [==============================] - 6s 6s/step - loss: 9.3651 - val_loss: 6.6107\nEpoch 13/50\n1/1 [==============================] - 6s 6s/step - loss: 9.3651 - val_loss: 6.6107\nEpoch 14/50\n1/1 [==============================] - 6s 6s/step - loss: 9.3651 - val_loss: 6.6107\nEpoch 15/50\n1/1 [==============================] - 6s 6s/step - loss: 9.3651 - val_loss: 6.6107\nEpoch 16/50\n1/1 [==============================] - 6s 6s/step - loss: 9.3651 - val_loss: 6.6107\nEpoch 17/50\n1/1 [==============================] - 6s 6s/step - loss: 9.3651 - val_loss: 6.6107\nEpoch 18/50\n1/1 [==============================] - 6s 6s/step - loss: 9.3651 - val_loss: 6.6107\nEpoch 19/50\n1/1 [==============================] - 6s 6s/step - loss: 9.3651 - val_loss: 6.6107\nEpoch 20/50\n1/1 [==============================] - 6s 6s/step - loss: 9.3651 - val_loss: 6.6107\nEpoch 21/50\n1/1 [==============================] - 6s 6s/step - loss: 9.3651 - val_loss: 6.6107\nEpoch 22/50\n1/1 [==============================] - 6s 6s/step - loss: 9.3651 - val_loss: 6.6107\nEpoch 23/50\n1/1 [==============================] - 6s 6s/step - loss: 9.3651 - val_loss: 6.6107\nEpoch 24/50\n1/1 [==============================] - 6s 6s/step - loss: 9.3651 - val_loss: 6.6107\nEpoch 25/50\n1/1 [==============================] - 6s 6s/step - loss: 9.3651 - val_loss: 6.6107\nEpoch 26/50\n1/1 [==============================] - 6s 6s/step - loss: 9.3651 - val_loss: 6.6107\nEpoch 27/50\n1/1 [==============================] - 6s 6s/step - loss: 9.3651 - val_loss: 6.6107\nEpoch 28/50\n1/1 [==============================] - 6s 6s/step - loss: 9.3651 - val_loss: 6.6107\nEpoch 29/50\n1/1 [==============================] - 6s 6s/step - loss: 9.3651 - val_loss: 6.6107\nEpoch 30/50\n1/1 [==============================] - 7s 7s/step - loss: 9.3651 - val_loss: 6.6107\nEpoch 31/50\n1/1 [==============================] - 6s 6s/step - loss: 9.3651 - val_loss: 6.6107\nEpoch 32/50\n1/1 [==============================] - 6s 6s/step - loss: 9.3651 - val_loss: 6.6107\nEpoch 33/50\n1/1 [==============================] - 6s 6s/step - loss: 9.3651 - val_loss: 6.6107\nEpoch 34/50\n1/1 [==============================] - 6s 6s/step - loss: 9.3651 - val_loss: 6.6107\nEpoch 35/50\n1/1 [==============================] - 6s 6s/step - loss: 9.3651 - val_loss: 6.6107\nEpoch 36/50\n1/1 [==============================] - 6s 6s/step - loss: 9.3651 - val_loss: 6.6107\nEpoch 37/50\n1/1 [==============================] - 6s 6s/step - loss: 9.3651 - val_loss: 6.6107\nEpoch 38/50\n1/1 [==============================] - 6s 6s/step - loss: 9.3651 - val_loss: 6.6107\nEpoch 39/50\n1/1 [==============================] - 6s 6s/step - loss: 9.3651 - val_loss: 6.6107\nEpoch 40/50\n1/1 [==============================] - 6s 6s/step - loss: 9.3651 - val_loss: 6.6107\nEpoch 41/50\n1/1 [==============================] - 6s 6s/step - loss: 9.3651 - val_loss: 6.6107\nEpoch 42/50\n1/1 [==============================] - 6s 6s/step - loss: 9.3651 - val_loss: 6.6107\nEpoch 43/50\n1/1 [==============================] - 6s 6s/step - loss: 9.3651 - val_loss: 6.6107\nEpoch 44/50\n1/1 [==============================] - 6s 6s/step - loss: 9.3651 - val_loss: 6.6107\nEpoch 45/50\n1/1 [==============================] - 6s 6s/step - loss: 9.3651 - val_loss: 6.6107\nEpoch 46/50\n1/1 [==============================] - 6s 6s/step - loss: 9.3651 - val_loss: 6.6107\nEpoch 47/50\n1/1 [==============================] - 6s 6s/step - loss: 9.3651 - val_loss: 6.6107\nEpoch 48/50\n1/1 [==============================] - 6s 6s/step - loss: 9.3651 - val_loss: 6.6107\nEpoch 49/50\n1/1 [==============================] - 6s 6s/step - loss: 9.3651 - val_loss: 6.6107\nEpoch 50/50\n1/1 [==============================] - 6s 6s/step - loss: 9.3651 - val_loss: 6.6107\n","output_type":"stream"},{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7ef1ec6032b0>"},"metadata":{}}]},{"cell_type":"code","source":"train_pred2 = siamese_network.predict([train_input_pairs_reshaped[:, 0], train_input_pairs_reshaped[:, 1]])\ntrain_pred2= np.round(train_pred1).flatten()\ntrain_accuracy2 = np.mean(train_pred2 == train_labels)\n\n# Calculate testing accuracy\ntest_pred2 = siamese_network.predict([test_input_pairs_reshaped[:, 0], test_input_pairs_reshaped[:, 1]])\ntest_pred2 = np.round(test_pred1).flatten()\ntest_accuracy2 = np.mean(test_pred2 == test_labels)\n\nprint(\"Training Accuracy: {:.2f}%\".format(train_accuracy2 * 100))\nprint(\"Testing Accuracy: {:.2f}%\".format(test_accuracy2 * 100))","metadata":{"execution":{"iopub.status.busy":"2023-06-03T14:32:29.952578Z","iopub.execute_input":"2023-06-03T14:32:29.953723Z","iopub.status.idle":"2023-06-03T14:32:33.673895Z","shell.execute_reply.started":"2023-06-03T14:32:29.953683Z","shell.execute_reply":"2023-06-03T14:32:33.672391Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 3s 3s/step\n1/1 [==============================] - 0s 199ms/step\nTraining Accuracy: 53.57%\nTesting Accuracy: 57.14%\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Lambda\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.losses import binary_crossentropy\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\n\n# Define the input shape\ninput_shape = (256, 256, 3)\n\n# Define the Siamese network architecture\ndef build_siamese_network(input_shape):\n    input_image = Input(shape=input_shape)\n\n    model = Conv2D(64, (10, 10), activation='relu')(input_image)\n    model = MaxPooling2D()(model)\n    model = Conv2D(128, (7, 7), activation='relu')(model)\n    model = MaxPooling2D()(model)\n    model = Conv2D(128, (4, 4), activation='relu')(model)\n    model = MaxPooling2D()(model)\n    model = Conv2D(256, (4, 4), activation='relu')(model)\n    model = Flatten()(model)\n    model = Dense(4096, activation='sigmoid')(model)\n\n    encoded_image = model\n\n    siamese_model = Model(input_image, encoded_image)\n    return siamese_model\n\n# Create the Siamese network model\nsiamese_model = build_siamese_network(input_shape)\n\n# Compile the model with appropriate loss and optimizer\nsiamese_model.compile(loss=binary_crossentropy, optimizer=Adam(learning_rate=0.001))\n\n# Generate some dummy training data\ntrain_input_pairs = np.random.randn(28, 2, *input_shape)\ntest_input_pairs = np.random.randn(7, 2, *input_shape)\ntrain_labels = np.random.randint(0, 2, size=(28,))\ntest_labels = np.random.randint(0, 2, size=(7,))\n\n# Reshape the input pairs for training\ntrain_input_pairs_reshaped = np.reshape(train_input_pairs, (train_input_pairs.shape[0], 2, *input_shape))\ntest_input_pairs_reshaped = np.reshape(test_input_pairs, (test_input_pairs.shape[0], 2, *input_shape))\n\n# Define a custom distance function for comparing the encoded features\ndef euclidean_distance(vectors):\n    vector1, vector2 = vectors\n    sum_squared = tf.reduce_sum(tf.square(vector1 - vector2), axis=1, keepdims=True)\n    return tf.sqrt(sum_squared)\n\n# Define the siamese network with the distance function\ninput_image_1 = Input(shape=input_shape)\ninput_image_2 = Input(shape=input_shape)\n\nencoded_image_1 = siamese_model(input_image_1)\nencoded_image_2 = siamese_model(input_image_2)\n\ndistance = Lambda(euclidean_distance)([encoded_image_1, encoded_image_2])\n\nsiamese_network = Model(inputs=[input_image_1, input_image_2], outputs=distance)\n\n# Compile the siamese network\nsiamese_network.compile(loss=binary_crossentropy, optimizer=Adam(learning_rate=0.0001))\n\nsiamese_network.fit([train_input_pairs_reshaped[:, 0], train_input_pairs_reshaped[:, 1]], train_labels, \n                    validation_data=([test_input_pairs_reshaped[:, 0], test_input_pairs_reshaped[:, 1]], test_labels), \n                    batch_size=32, epochs=80)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-06-03T14:37:49.503577Z","iopub.execute_input":"2023-06-03T14:37:49.504781Z","iopub.status.idle":"2023-06-03T14:46:23.862508Z","shell.execute_reply.started":"2023-06-03T14:37:49.504744Z","shell.execute_reply":"2023-06-03T14:46:23.861320Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"Epoch 1/80\n1/1 [==============================] - 9s 9s/step - loss: 1.5948 - val_loss: 0.9890\nEpoch 2/80\n1/1 [==============================] - 6s 6s/step - loss: 0.5826 - val_loss: 0.8248\nEpoch 3/80\n1/1 [==============================] - 6s 6s/step - loss: 0.8625 - val_loss: 0.7274\nEpoch 4/80\n1/1 [==============================] - 6s 6s/step - loss: 0.6759 - val_loss: 0.6728\nEpoch 5/80\n1/1 [==============================] - 6s 6s/step - loss: 0.5427 - val_loss: 0.6412\nEpoch 6/80\n1/1 [==============================] - 6s 6s/step - loss: 0.4340 - val_loss: 0.6251\nEpoch 7/80\n1/1 [==============================] - 6s 6s/step - loss: 0.3330 - val_loss: 0.6173\nEpoch 8/80\n1/1 [==============================] - 6s 6s/step - loss: 0.2289 - val_loss: 0.6148\nEpoch 9/80\n1/1 [==============================] - 6s 6s/step - loss: 0.1236 - val_loss: 0.6171\nEpoch 10/80\n1/1 [==============================] - 6s 6s/step - loss: 0.0932 - val_loss: 0.6155\nEpoch 11/80\n1/1 [==============================] - 6s 6s/step - loss: 0.0770 - val_loss: 0.6133\nEpoch 12/80\n1/1 [==============================] - 6s 6s/step - loss: 0.0744 - val_loss: 0.6101\nEpoch 13/80\n1/1 [==============================] - 6s 6s/step - loss: 0.0760 - val_loss: 0.6070\nEpoch 14/80\n1/1 [==============================] - 6s 6s/step - loss: 0.0744 - val_loss: 0.6037\nEpoch 15/80\n1/1 [==============================] - 6s 6s/step - loss: 0.0646 - val_loss: 0.6007\nEpoch 16/80\n1/1 [==============================] - 6s 6s/step - loss: 0.0501 - val_loss: 0.5988\nEpoch 17/80\n1/1 [==============================] - 6s 6s/step - loss: 0.0372 - val_loss: 0.5982\nEpoch 18/80\n1/1 [==============================] - 6s 6s/step - loss: 0.0306 - val_loss: 0.5988\nEpoch 19/80\n1/1 [==============================] - 6s 6s/step - loss: 0.0303 - val_loss: 0.6009\nEpoch 20/80\n1/1 [==============================] - 6s 6s/step - loss: 0.0296 - val_loss: 0.6046\nEpoch 21/80\n1/1 [==============================] - 6s 6s/step - loss: 0.0256 - val_loss: 0.6098\nEpoch 22/80\n1/1 [==============================] - 6s 6s/step - loss: 0.0199 - val_loss: 0.6148\nEpoch 23/80\n1/1 [==============================] - 6s 6s/step - loss: 0.0223 - val_loss: 0.6060\nEpoch 24/80\n1/1 [==============================] - 6s 6s/step - loss: 0.0193 - val_loss: 0.6055\nEpoch 25/80\n1/1 [==============================] - 6s 6s/step - loss: 0.0184 - val_loss: 0.6094\nEpoch 26/80\n1/1 [==============================] - 6s 6s/step - loss: 0.0152 - val_loss: 0.6159\nEpoch 27/80\n1/1 [==============================] - 6s 6s/step - loss: 0.0133 - val_loss: 0.6243\nEpoch 28/80\n1/1 [==============================] - 6s 6s/step - loss: 0.0124 - val_loss: 0.6344\nEpoch 29/80\n1/1 [==============================] - 6s 6s/step - loss: 0.0176 - val_loss: 0.6193\nEpoch 30/80\n1/1 [==============================] - 6s 6s/step - loss: 0.0136 - val_loss: 0.6197\nEpoch 31/80\n1/1 [==============================] - 6s 6s/step - loss: 0.0120 - val_loss: 0.6264\nEpoch 32/80\n1/1 [==============================] - 6s 6s/step - loss: 0.0095 - val_loss: 0.6353\nEpoch 33/80\n1/1 [==============================] - 6s 6s/step - loss: 0.0109 - val_loss: 0.6282\nEpoch 34/80\n1/1 [==============================] - 6s 6s/step - loss: 0.0096 - val_loss: 0.6290\nEpoch 35/80\n1/1 [==============================] - 6s 6s/step - loss: 0.0082 - val_loss: 0.6329\nEpoch 36/80\n1/1 [==============================] - 6s 6s/step - loss: 0.0086 - val_loss: 0.6233\nEpoch 37/80\n1/1 [==============================] - 6s 6s/step - loss: 0.0085 - val_loss: 0.6256\nEpoch 38/80\n1/1 [==============================] - 6s 6s/step - loss: 0.0074 - val_loss: 0.6308\nEpoch 39/80\n1/1 [==============================] - 6s 6s/step - loss: 0.0072 - val_loss: 0.6383\nEpoch 40/80\n1/1 [==============================] - 6s 6s/step - loss: 0.0069 - val_loss: 0.6466\nEpoch 41/80\n1/1 [==============================] - 6s 6s/step - loss: 0.0077 - val_loss: 0.6410\nEpoch 42/80\n1/1 [==============================] - 6s 6s/step - loss: 0.0060 - val_loss: 0.6408\nEpoch 43/80\n1/1 [==============================] - 6s 6s/step - loss: 0.0057 - val_loss: 0.6440\nEpoch 44/80\n1/1 [==============================] - 6s 6s/step - loss: 0.0057 - val_loss: 0.6496\nEpoch 45/80\n1/1 [==============================] - 6s 6s/step - loss: 0.0064 - val_loss: 0.6490\nEpoch 46/80\n1/1 [==============================] - 6s 6s/step - loss: 0.0054 - val_loss: 0.6506\nEpoch 47/80\n1/1 [==============================] - 6s 6s/step - loss: 0.0051 - val_loss: 0.6534\nEpoch 48/80\n1/1 [==============================] - 6s 6s/step - loss: 0.0056 - val_loss: 0.6514\nEpoch 49/80\n1/1 [==============================] - 6s 6s/step - loss: 0.0051 - val_loss: 0.6527\nEpoch 50/80\n1/1 [==============================] - 6s 6s/step - loss: 0.0053 - val_loss: 0.6560\nEpoch 51/80\n1/1 [==============================] - 6s 6s/step - loss: 0.0052 - val_loss: 0.6556\nEpoch 52/80\n1/1 [==============================] - 6s 6s/step - loss: 0.0055 - val_loss: 0.6581\nEpoch 53/80\n1/1 [==============================] - 6s 6s/step - loss: 0.0053 - val_loss: 0.6541\nEpoch 54/80\n1/1 [==============================] - 6s 6s/step - loss: 0.0058 - val_loss: 0.6536\nEpoch 55/80\n1/1 [==============================] - 6s 6s/step - loss: 0.0052 - val_loss: 0.6561\nEpoch 56/80\n1/1 [==============================] - 6s 6s/step - loss: 0.0053 - val_loss: 0.6605\nEpoch 57/80\n1/1 [==============================] - 6s 6s/step - loss: 0.0056 - val_loss: 0.6599\nEpoch 58/80\n1/1 [==============================] - 6s 6s/step - loss: 0.0052 - val_loss: 0.6617\nEpoch 59/80\n1/1 [==============================] - 6s 6s/step - loss: 0.0049 - val_loss: 0.6653\nEpoch 60/80\n1/1 [==============================] - 6s 6s/step - loss: 0.0055 - val_loss: 0.6636\nEpoch 61/80\n1/1 [==============================] - 6s 6s/step - loss: 0.0051 - val_loss: 0.6646\nEpoch 62/80\n1/1 [==============================] - 6s 6s/step - loss: 0.0052 - val_loss: 0.6673\nEpoch 63/80\n1/1 [==============================] - 6s 6s/step - loss: 0.0057 - val_loss: 0.6541\nEpoch 64/80\n1/1 [==============================] - 6s 6s/step - loss: 0.0059 - val_loss: 0.6570\nEpoch 65/80\n1/1 [==============================] - 6s 6s/step - loss: 0.0051 - val_loss: 0.6627\nEpoch 66/80\n1/1 [==============================] - 6s 6s/step - loss: 0.0051 - val_loss: 0.6698\nEpoch 67/80\n1/1 [==============================] - 6s 6s/step - loss: 0.0069 - val_loss: 0.6525\nEpoch 68/80\n1/1 [==============================] - 6s 6s/step - loss: 0.0065 - val_loss: 0.6626\nEpoch 69/80\n1/1 [==============================] - 6s 6s/step - loss: 0.0052 - val_loss: 0.6780\nEpoch 70/80\n1/1 [==============================] - 6s 6s/step - loss: 0.0099 - val_loss: 0.6624\nEpoch 71/80\n1/1 [==============================] - 6s 6s/step - loss: 0.0069 - val_loss: 0.6709\nEpoch 72/80\n1/1 [==============================] - 6s 6s/step - loss: 0.0057 - val_loss: 0.6651\nEpoch 73/80\n1/1 [==============================] - 6s 6s/step - loss: 0.0067 - val_loss: 0.6681\nEpoch 74/80\n1/1 [==============================] - 6s 6s/step - loss: 0.0057 - val_loss: 0.6770\nEpoch 75/80\n1/1 [==============================] - 6s 6s/step - loss: 0.0089 - val_loss: 0.6659\nEpoch 76/80\n1/1 [==============================] - 6s 6s/step - loss: 0.0057 - val_loss: 0.6689\nEpoch 77/80\n1/1 [==============================] - 6s 6s/step - loss: 0.0055 - val_loss: 0.6787\nEpoch 78/80\n1/1 [==============================] - 6s 6s/step - loss: 0.0053 - val_loss: 0.6903\nEpoch 79/80\n1/1 [==============================] - 6s 6s/step - loss: 0.0068 - val_loss: 0.6743\nEpoch 80/80\n1/1 [==============================] - 6s 6s/step - loss: 0.0064 - val_loss: 0.6739\n","output_type":"stream"},{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7ef1ec2af880>"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\n# Generate predictions for the testing data\ntest_pred1 = siamese_network.predict([test_input_pairs_reshaped[:, 0], test_input_pairs_reshaped[:, 1]])\ntest_pred1 = np.round(test_pred1).flatten()\n\n# Create the confusion matrix\ncm = confusion_matrix(test_labels, test_pred1)\n\n# Print the confusion matrix\nprint(\"Confusion Matrix:\")\nprint(cm)","metadata":{"execution":{"iopub.status.busy":"2023-06-03T15:16:48.295673Z","iopub.execute_input":"2023-06-03T15:16:48.296306Z","iopub.status.idle":"2023-06-03T15:16:50.998224Z","shell.execute_reply.started":"2023-06-03T15:16:48.296269Z","shell.execute_reply":"2023-06-03T15:16:50.997020Z"},"trusted":true},"execution_count":1,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m confusion_matrix\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Generate predictions for the testing data\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m test_pred1 \u001b[38;5;241m=\u001b[39m \u001b[43msiamese_network\u001b[49m\u001b[38;5;241m.\u001b[39mpredict([test_input_pairs_reshaped[:, \u001b[38;5;241m0\u001b[39m], test_input_pairs_reshaped[:, \u001b[38;5;241m1\u001b[39m]])\n\u001b[1;32m      5\u001b[0m test_pred1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mround(test_pred1)\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Create the confusion matrix\u001b[39;00m\n","\u001b[0;31mNameError\u001b[0m: name 'siamese_network' is not defined"],"ename":"NameError","evalue":"name 'siamese_network' is not defined","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}